{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from retrying import retry\n",
    "\n",
    "# System prompt (restored)\n",
    "system_prompt = \"\"\" prompt    \"\"\"\n",
    "\n",
    "@retry(stop_max_attempt_number=5, wait_fixed=2000)\n",
    "def call_api(messages, max_tokens=8192, timeout=60):\n",
    "    try:\n",
    "        response = dashscope.Generation.call(\n",
    "            api_key='xxxxxx',\n",
    "            model='xxxxx',\n",
    "            messages=messages,\n",
    "            result_format='message',\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.0,\n",
    "            timeout=timeout  # Note: Confirm if dashscope supports this\n",
    "        )\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            return response.output.choices[0].message.content.strip()\n",
    "        else:\n",
    "            raise Exception(f\"API error: {response.code} - {response.message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def process_batch(batch_questions, batch_idx, max_input_length=58000):\n",
    "    batch_text = \"\\n\".join([f\"Problem {i+1}: {q}\" for i, q in enumerate(batch_questions)])\n",
    "    \n",
    "    if len(batch_text) > max_input_length:\n",
    "        trimmed_batch = []\n",
    "        current_length = 0\n",
    "        for i, q in enumerate(batch_questions):\n",
    "            problem_text = f\"Problem {i+1}: {q}\"\n",
    "            if current_length + len(problem_text) + 1 <= max_input_length:\n",
    "                trimmed_batch.append(q)\n",
    "                current_length += len(problem_text) + 1\n",
    "            else:\n",
    "                print(f\"Batch {batch_idx}: Trimmed to {len(trimmed_batch)} problems, input length {current_length}\")\n",
    "                break\n",
    "        batch_questions = trimmed_batch\n",
    "        batch_text = \"\\n\".join([f\"Problem {i+1}: {q}\" for i, q in enumerate(batch_questions)])\n",
    "\n",
    "    print(f\"Batch {batch_idx}: Processing {len(batch_questions)} problems, {len(batch_text)} chars\")\n",
    "    messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': batch_text}]\n",
    "    try:\n",
    "        response = call_api(messages)\n",
    "        replies = [r.strip() for r in response.split(\"----\") if r.strip()]\n",
    "        print(f\"Batch {batch_idx}: Received {len(replies)}/{len(batch_questions)} replies\")\n",
    "        return replies + [None] * (len(batch_questions) - len(replies)) if len(replies) < len(batch_questions) else replies\n",
    "    except Exception as e:\n",
    "        print(f\"Batch {batch_idx}: Failed - {e}\")\n",
    "        return [None] * len(batch_questions)\n",
    "\n",
    "def save_results(results, output_file_path):\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(valid_results, outfile, ensure_ascii=False, indent=4)\n",
    "    print(f\"Saved {len(valid_results)}/{len(results)} valid results\")\n",
    "\n",
    "def process_file(input_file_path, output_file_path, initial_batch_size=5, max_workers=4, test_limit=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Read input file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "    questions = [entry.get(\"problem\", \"\") for entry in data if entry.get(\"problem\", \"\")][:test_limit]\n",
    "    if not questions:\n",
    "        print(\"Error: No valid problems found\")\n",
    "        return\n",
    "\n",
    "    # Dynamic batch sizing\n",
    "    avg_length = sum(len(q) for q in questions) / len(questions)\n",
    "    batch_size = max(1, min(initial_batch_size, int(58000 / (avg_length + 50))))\n",
    "    batches = [questions[i:i + batch_size] for i in range(0, len(questions), batch_size)]\n",
    "    print(f\"Testing {len(questions)} problems, batch_size={batch_size}, batches={len(batches)}, workers={max_workers}\")\n",
    "\n",
    "    # Process batches\n",
    "    results = [None] * len(questions)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_batch = {executor.submit(process_batch, b, i + 1): (i, b) for i, b in enumerate(batches)}\n",
    "        for future in as_completed(future_to_batch):\n",
    "            batch_idx, batch_questions = future_to_batch[future]\n",
    "            try:\n",
    "                batch_replies = future.result()\n",
    "                start_idx = batch_idx * batch_size\n",
    "                for j, reply in enumerate(batch_replies):\n",
    "                    idx = start_idx + j\n",
    "                    if idx < len(results):\n",
    "                        if reply:\n",
    "                            try:\n",
    "                                results[idx] = json.loads(reply)\n",
    "                            except json.JSONDecodeError:\n",
    "                                print(f\"Batch {batch_idx}, Problem {idx + 1}: Invalid JSON - {reply[:100]}...\")\n",
    "                        else:\n",
    "                            print(f\"Batch {batch_idx}, Problem {idx + 1}: No reply received\")\n",
    "            except Exception as e:\n",
    "                print(f\"Batch {batch_idx} failed entirely: {e}\")\n",
    "\n",
    "    # Save results\n",
    "    save_results(results, output_file_path)\n",
    "    print(f\"Processed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file_path = r\"x:xxxxxx\"\n",
    "    output_file_path = r\"x:xxxxx\"\n",
    "    process_file(input_file_path, output_file_path, initial_batch_size=5, max_workers=4, test_limit=100)\n",
    "    print(\"Testing complete!\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diamond",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
